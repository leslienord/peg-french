# Les bases du prompting

## Prompts basiques

Vous pouvez obtenir de nombreux résultats avec de simples prompts, mais la qualité des résultats dépend de la quantité d'informations que vous fournissez et de la qualité de leur rédaction. Un prompt peut contenir des informations telles que l'*instruction* ou la *question* que vous transmettez au modèle, ainsi que d'autres détails tels que le *contexte*, les *inputs* [TO DO] ou les *exemples*. Vous pouvez utiliser ces éléments pour mieux instruire le modèle [A REVOIR] et obtenir de meilleurs résultats.

Commençons par un exemple de base d'un simple prompt :

*Prompt:*
```
Le ciel est
```

*Output:*
```
bleu

Le ciel est bleu par temps clair. Par temps nuageux, le ciel peut être gris ou blanc.
```

Comme vous pouvez le constater, le modèle de langage produit une séquence de chaînes de caractères qui ont un sens dans le contexte "Le ciel est". Le résultat peut être inattendu ou éloigné de la tâche que nous voulons accomplir. 

Cet exemple de base souligne également la nécessité de fournir davantage de contexte ou d'instructions sur ce que nous voulons accomplir.

Essayons de l'améliorer un peu :

*Prompt:*
```
Complétez la phrase : 

Le ciel est
```

*Output:*

```
si beau aujourd'hui.
```

Est-ce mieux ? Nous avons demandé au modèle de compléter la phrase, le résultat semble donc bien meilleur puisqu'il suit exactement ce que nous lui avons demandé de faire ("compléter la phrase"). Cette approche, qui consiste à concevoir des prompts optimaux pour demander au modèle d'effectuer une tâche, est appelée **ingénierie des prompts**. 

L'exemple ci-dessus est une illustration de base de ce qui est possible avec les LLMs aujourd'hui. Les LLMs d'aujourd'hui sont capables d'effectuer toutes sortes de tâches avancées allant du résumé de texte au raisonnement mathématique en passant par la génération de code.

## Formatage de prompt

Nous avons essayé un prompt très simple ci-dessus. Un prompt standard a le format suivant :

```
<Question> ?
```

ou 

```
<Instruction>
```
 
Ceci peut être formaté dans un format Question-Réponse (QR), qui est standard dans de nombreux ensembles de données QR, comme suit :

```
Q : <Question> ?
R : 
```

Lorsqu'un prompt est sollicité de la manière décrite ci-dessus, on parle également de "zero-shot prompting"[TO DO?], ce qui signifie que vous demandez directement au prompt de répondre sans exemples ou démonstrations de la tâche que vous souhaitez qu'il effectue. Certains LLMs sont capables d'effectuer des "zero-shot prompting", mais cela dépend de la complexité et de la connaissance de la tâche à accomplir. 

Compte tenu du format standard mentionné ci-dessus, une technique populaire et efficace est appelée "few-shot prompting",[TO DO?] qui consiste à fournir des exemples (c'est-à-dire des démonstrations). Les "few-shot prompting" [TO DO?] peuvent être formulées comme suit :

```
<Question> ?
<Réponse>
<Question> ?
<Réponse>
<Question> ?
<Réponse>
<Question> ?

```

La version au format QR ressemblerait à ceci :

```
Q : <Question> ?
R : <Réponse>
Q : <Question> ?
R : <Réponse>
Q : <Question> ?
R : <Réponse>
Q : <Question> ?
R :
```

N'oubliez pas qu'il n'est pas obligatoire d'utiliser le format QR. Le format du prompt dépend de la tâche à accomplir. Par exemple, vous pouvez effectuer une simple tâche de classification et donner des exemples qui illustrent la tâche comme suit :

*Prompt:*
```

C'est génial ! // Positif
C'est mauvais ! // Négatif
Wow ce film était génial ! // Positif
Quel spectacle horrible ! //
```

*Output:*
```
Négatif
```

Les messages courts permettent l'apprentissage en contexte, c'est-à-dire la capacité des modèles de langage à apprendre des tâches à partir de quelques démonstrations.
